{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wildcard queries and tolerant retrieval\n",
    "The aim of wildcard queries is to support search for all the words that match a given pattern in order to be tolerant with respect to the form of words in the query.\n",
    "\n",
    "### Example:\n",
    "When searching for <code>p*er</code>, we aim at matching both <code>paper</code> and <code>player</code>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Permuterm index\n",
    "Add a special symbol like <code>#</code> to each token with the aim of marking the end of the word.\n",
    "Then, we create a key in the permuterm index for each rotation of a term moving left the symbol <code>#</code>\n",
    "\n",
    "### Example:\n",
    "- paper# $\\rightarrow$ paper#, aper#p, per#pa, er#pap, r#pape, #paper\n",
    "\n",
    "Given a wildcard query including the symbol <code>\\*</code>, we now rotate it to have <code>\\*</code> in the end of the string and search all the tokens starting with it in the permuterm index (using a b-tree).\n",
    "\n",
    "### Example:\n",
    "- <code>p\\*er#</code> $\\rightarrow$ <code>er#p\\*</code>\n",
    "\n",
    "When working with multiple wildcards, e.g. <code>pl\\*ie\\*rs</code>, we first work with the first and the last wildcards as shown above, and then we filter out all the terms not containing the other part of the query.\n",
    "\n",
    "### Example:\n",
    "Search for <code>pl\\*rs</code> and then filter out all terms not containing a <code>ie</code>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Permuterm index in the cranfield dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "I = pymongo.MongoClient()['inforet']['cran_tokens']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = {'$group': {'_id': None, 'tokens': {'$addToSet': '$text'}}}\n",
    "tokens = [x['tokens'] for x in I.aggregate([g])][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def permuterm(token):\n",
    "    t = token + '#'\n",
    "    p = []\n",
    "    for i in range(-1, -(len(t)+1), -1):\n",
    "        p.append(t[i:] + t[:i])\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = defaultdict(lambda: None)\n",
    "for token in tokens:\n",
    "    for p in permuterm(token):\n",
    "        P[p] = token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = [x for x in permuterm('po*l') if x.endswith('*')][0][:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l#powerfu powerful\n",
      "l#polyaxia polyaxial\n",
      "l#potentia potential\n",
      "l#powel powell\n",
      "l#polynomia polynomial\n"
     ]
    }
   ],
   "source": [
    "for k, v in P.items():\n",
    "    if k.startswith(query):\n",
    "        print(k, v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k-gram queries\n",
    "A further strategy for wildcard queries is to index k-grams in tokens. For example, with 3-grams, we index the term <code>#play#</code> under <code>#pl</code>, <code>pla</code>, <code>lay</code>, and <code>ay#</code>.\n",
    "\n",
    "According to this approach, we process the wildcard query <code>pl\\*er</code> by running the boolean query <code>#pl AND er#</code> and then post-processing the resulting tokens to filter out wrong terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.util import ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kgrams(token, k=2):\n",
    "    return [\"\".join(x) for x in ngrams(\"#\" + token + \"#\", k)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = defaultdict(lambda: set())\n",
    "for token in tokens:\n",
    "    for kg in kgrams(token, k=3):\n",
    "        K[kg].add(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = []\n",
    "for x in \"#pl*ed#\".split('*'):\n",
    "    if len(x) > 3:\n",
    "        query += [\"\".join(y) for y in ngrams(x, 3)]\n",
    "    elif len(x) == 3:\n",
    "        query.append(x)        \n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = K[query[0]]\n",
    "for q in query[1:]:\n",
    "    r = r.intersection(K[q])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'placed', 'played', 'plied', 'plotted'}"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
