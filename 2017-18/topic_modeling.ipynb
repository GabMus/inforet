{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Short tutorial on gensim for topic modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from benchmark.ipynb\n",
      "importing Jupyter notebook from classifiers.ipynb\n"
     ]
    }
   ],
   "source": [
    "import nbimporter\n",
    "from benchmark import ImageTags\n",
    "import numpy as np\n",
    "from IPython.core.display import display, HTML, Image\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import itertools\n",
    "from sklearn import metrics\n",
    "from gensim import corpora, models\n",
    "from classifiers import Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cm_plot(ax, classes, CM, title, figure):\n",
    "    im = ax.imshow(CM, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    divider = make_axes_locatable(ax)\n",
    "    cax = divider.append_axes('right', size='5%', pad=0.05)\n",
    "    figure.colorbar(im, cax=cax, orientation='vertical')\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    ax.set_xticks(tick_marks)\n",
    "    ax.set_xticklabels(classes, rotation=90, fontsize=12)\n",
    "    ax.set_yticks(tick_marks)\n",
    "    ax.set_yticklabels(classes, rotation=0, fontsize=12)\n",
    "    ax.set_title(title, fontsize=16)\n",
    "    thresh = CM.max() / 2.\n",
    "    for i, j in itertools.product(range(CM.shape[0]), range(CM.shape[1])):\n",
    "        ax.text(j, i, CM[i, j], horizontalalignment=\"center\",\n",
    "                 color=\"white\" if CM[i, j] > thresh else \"black\", fontsize=12)\n",
    "    ax.set_ylabel('True label', fontsize=16)\n",
    "    ax.set_xlabel('Predicted label', fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "I = ImageTags('inforet', 'googleimages', url='image_thumbnail_url', \n",
    "              selection=None)\n",
    "C = Classifier(I, 'category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Create dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = corpora.Dictionary(I.tag_stream())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(1694 unique tokens: [u'mackerel', u'dynamic', u'dynasty', u'four', u'sleep']...)\n",
      "[(u'mackerel', 1488), (u'dynamic', 1227), (u'dynasty', 576), (u'four', 986), (u'sleep', 201), (u'hanging', 1311), (u'captain', 1314), (u'aggression', 123), (u'cellular telephone', 1062), (u'sports fan', 532)]\n"
     ]
    }
   ],
   "source": [
    "print dictionary\n",
    "print dictionary.token2id.items()[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gensim bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'balcony', u'step', u'tourist', u'town', u'window', u'house', u'sight', u'scene', u'urban', u'street', u'building', u'travel', u'outdoors', u'no person', u'tourism', u'architecture', u'sky', u'city', u'vacation', u'modern']\n",
      "[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1)]\n"
     ]
    }
   ],
   "source": [
    "doc = [I.tags[j] for j, x in enumerate(I.M[0]) if x > 0]\n",
    "print doc\n",
    "print dictionary.doc2bow(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create a corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IMG(object):\n",
    "    \n",
    "    def __init__(self, imagetags, dictionary):\n",
    "        self.I, self.D = imagetags, dictionary\n",
    "    \n",
    "    def __iter__(self):\n",
    "        for doc in self.I.tag_stream():\n",
    "            yield self.D.doc2bow(doc)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.I.M.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = IMG(I, dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Apply transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = models.TfidfModel(corpus) # Model trained by corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_tfidf = tfidf[corpus] # New corpus transformed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Create models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsi = models.LsiModel(corpus_tfidf, id2word=corpus.D, num_topics=4)\n",
    "lsi_corpus = lsi[corpus_tfidf]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Term topic matrix with shape (num_topics, vocabulary_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1.75126356e-01,   1.25651644e-03,   1.73422478e-01, ...,\n",
       "        -1.27798017e-04,  -6.04423152e-05,  -3.34730780e-04])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsi.get_topics()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'architecture', -0.16993642655264315), (u'city', -0.16763504784756825), (u'building', -0.16475685422558198), (u'sky', -0.16325962862914245), (u'travel', -0.15877929023973955), (u'outdoors', -0.15737438274741994), (u'cityscape', -0.13729080175629554), (u'water', -0.13681424865454558), (u'urban', -0.13579093700875691), (u'tourism', -0.13034862699789343)]\n",
      "[(u'architecture', 0.17512635562620024), (u'ball', -0.17361976931925477), (u'building', 0.17342247786649248), (u'athlete', -0.16899756745575856), (u'competition', -0.16650915762269461), (u'city', 0.16166427113283136), (u'game', -0.16055728563471894), (u'sky', 0.15937670108006333), (u'sports equipment', -0.15293968610044234), (u'cityscape', 0.1525133463040993)]\n"
     ]
    }
   ],
   "source": [
    "print lsi.show_topic(0)\n",
    "print lsi.show_topic(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Document to topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsi_predicted = []\n",
    "for lsi_vec in lsi_corpus:\n",
    "    values = np.array([np.abs(x) for i, x in lsi_vec])\n",
    "    lsi_predicted.append(np.argmax(values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = models.LdaModel(corpus_tfidf, id2word=corpus.D, num_topics=4)\n",
    "lda_corpus = lda[corpus_tfidf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'desktop', 0.0088255135), (u'leather', 0.0086313877), (u'vector', 0.0086098295), (u'illustration', 0.0084475456), (u'sport', 0.0082818214), (u'exercise', 0.008073207), (u'isolated', 0.0079897512), (u'image', 0.007886583), (u'symbol', 0.0078473194), (u'recreation', 0.0078245196)]\n",
      "[(u'woman', 0.0087118978), (u'group', 0.0070632999), (u'crowd', 0.0065643089), (u'many', 0.0065352451), (u'people', 0.0063774819), (u'portrait', 0.0062129386), (u'adult', 0.0061985068), (u'girl', 0.0061666495), (u'police', 0.0058442648), (u'wear', 0.005840438)]\n"
     ]
    }
   ],
   "source": [
    "print lda.show_topic(0)\n",
    "print lda.show_topic(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_predicted = []\n",
    "for lda_vec in lda_corpus:\n",
    "    values = np.array([x for i, x in lda_vec])\n",
    "    lda_predicted.append(np.argmax(values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdp = models.HdpModel(corpus_tfidf, id2word=corpus.D)\n",
    "hdp_corpus = hdp[corpus_tfidf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'road', 0.0045546237840529413), (u'electricity', 0.0039035546718500843), (u'tee', 0.0038708281713159668), (u'sparkling', 0.0035571509700796423), (u'aid', 0.0035143649771242767), (u'population', 0.003468160154639108), (u'bubble', 0.0034430965356653676), (u'splash', 0.0033961373739557314), (u'town', 0.0033733546155359745), (u'steps', 0.0032430862491531738), (u'marina', 0.0032105925212552932), (u'window', 0.0030610754268700279), (u'cap', 0.0030609016328958273), (u'drive', 0.0029993192467058492), (u'skyscraper', 0.0029848762293942575), (u'tennis player', 0.0029597627088877648), (u'site', 0.002915973467748465), (u'health', 0.0028844433178560093), (u'clean', 0.0028162584787746951), (u'barricade', 0.002814648132703444)]\n",
      "[(u'disjunct', 0.004665056703012131), (u'net', 0.003455718469394126), (u'salmon', 0.0033995429374478951), (u'moment', 0.0033651450238194438), (u'sushi', 0.0033335410927258849), (u'mare', 0.0032570436231149414), (u'figurine', 0.0032355060654377832), (u'ban', 0.0032232324922709422), (u'crop', 0.003205358275279293), (u'planning', 0.0031922505239315594), (u'player', 0.003167543220877425), (u'picture frame', 0.0031365518745671709), (u'hanging', 0.0030825246803593102), (u'shuttlecock', 0.0029659289846745308), (u'mountain peak', 0.0029400811813690229), (u'opposition', 0.0028476825792437834), (u'silk', 0.002810045055001095), (u'away abroad', 0.0028023164232213195), (u'crowd', 0.0027650158572992845), (u'smudge', 0.0027361871503257754)]\n"
     ]
    }
   ],
   "source": [
    "print hdp.show_topic(0)\n",
    "print hdp.show_topic(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdp_predicted = []\n",
    "for hdp_vec in hdp_corpus:\n",
    "    values = np.array([x for i, x in hdp_vec])\n",
    "    hdp_predicted.append(np.argmax(values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print hdp_predicted[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><td>LSI</td><td>0.216</td><td>0.189</td><td>0.218</td></tr><tr><td>LDA</td><td>0.142</td><td>0.119</td><td>0.143</td></tr><tr><td>HDP</td><td>0.0</td><td>0.004</td><td>0.001</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "experiments = ['LSI', 'LDA', 'HDP']\n",
    "clusters = [lsi_predicted, lda_predicted, hdp_predicted]\n",
    "\n",
    "rows = []\n",
    "for i, e in enumerate(experiments):\n",
    "    data = [\n",
    "        e, \n",
    "        round(metrics.adjusted_mutual_info_score(C.categories, clusters[i]), 3),\n",
    "        round(metrics.adjusted_rand_score(C.categories, clusters[i]), 3),\n",
    "        round(metrics.homogeneity_score(C.categories, clusters[i]), 3)\n",
    "    ]\n",
    "    row = \"<tr>\" + \"\".join([\"<td>{}</td>\".format(x) for x in data]) + \"</tr>\"\n",
    "    rows.append(row)\n",
    "table = \"<table>{}</table>\".format(\"\".join(rows))\n",
    "display(HTML(table))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
